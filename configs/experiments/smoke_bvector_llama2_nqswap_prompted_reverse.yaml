name: smoke_bvector_llama2_nqswap_prompted_reverse
model: llama2_7b
dataset: nq_swap_hf
method: composite
model_overrides:
  device_map: "auto"
  dtype: "bfloat16"
dataset_overrides:
  cache_dir: ".hf_cache"
  max_rows: 4096
  k_shot: 3
  demo_pool_size: 128
  demonstrations_org_context: true
  demonstrations_org_answer: true
  test_example_org_context: false
  train_use_answer: false
  train_include_param_context: false
  context_template: "context: {context}\nquestion: {question}\nanswer:"
  param_template: "question: {question}\nanswer:"
method_overrides:
  estimator:
    type: diffmean
    direction_path: results/bvectors/llama2_nqswap_prompted_sparematch_reverse_n256_layer{layer}.pt
  transform:
    normalize: true
  op:
    type: add
    scale: 1.5
  schedule:
    layers: [12, 13, 14, 15]
    token_position: last
run:
  seed: 42
  factors: [1.0]
  splits:
    train: train
    eval: eval
    test: test
  train:
    group_pos: param
    group_neg: context
    max_examples: 256
    batch_size: 4
  eval:
    group: context
    split: eval
    test_split: test
    max_examples: 64
    metrics:
      - exact_match
    generation:
      max_new_tokens: 4
      do_sample: false
      max_prompt_tokens: 2048
